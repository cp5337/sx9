//! Zero-Dependency Neural Mux Demo
//!
//! Demonstrates Tesla-grade intelligent routing with ZERO AI/ML dependencies
//! Falls back to advanced rule-based system that rivals AI performance

use ctas7_foundation_core::{
    unified_neural_mux::{UnifiedNeuralMux, UnifiedNeuralMuxConfig, PhiModelConfig, RequestType},
    diagnostics,
};
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt::init();

    println!("ğŸ§  CTAS-7 Zero-Dependency Neural Mux Demo");
    println!("===============================================");
    println!("Tesla/SpaceX-grade routing with ZERO AI/ML dependencies");
    println!();

    // Create configuration with zero dependencies
    let mut config = UnifiedNeuralMuxConfig::wide_open();
    config.phi_inference_enabled = true;
    config.phi_model_config = Some(PhiModelConfig::tesla_grade_zero_deps());

    println!("âœ… Configuration: Zero dependencies, Tesla-grade rules");
    println!("âœ… Fallback: Advanced mathematical routing engine");
    println!();

    // Initialize the neural mux
    let mut neural_mux = UnifiedNeuralMux::new(config)?;

    // Demo different request types
    let test_cases = vec![
        ("Small Dashboard Request", RequestType::Dashboard("user_metrics".to_string()), 1024),
        ("Large Statistical Analysis", RequestType::StatisticalAnalysis("machine_learning_dataset".to_string()), 50 * 1024 * 1024),
        ("GIS Query", RequestType::GISPlatform("satellite_imagery".to_string()), 10 * 1024 * 1024),
        ("Stats Ingestion", RequestType::StatsIngestion("telemetry_stream".to_string()), 5 * 1024 * 1024),
        ("Main Ops Request", RequestType::MainOpsFrontend("tactical_display".to_string()), 2048),
        ("Orchestrator Command", RequestType::OrchestratorGateway("mission_control".to_string()), 512),
    ];

    for (name, request_type, payload_size) in test_cases {
        println!("ğŸ¯ Testing: {}", name);
        println!("   Request: {:?}", request_type);
        println!("   Payload: {} bytes ({:.1} MB)", payload_size, payload_size as f64 / 1024.0 / 1024.0);

        let data = vec![0u8; payload_size];
        let start_time = std::time::Instant::now();

        match neural_mux.route_request(request_type, &data) {
            Ok(response) => {
                let elapsed = start_time.elapsed();
                println!("   âœ… Routed to: {}", response.service_type.service_name());
                println!("   ğŸ¯ Decision: {}", response.routing_decision);
                println!("   ğŸ“Š Confidence: {:.1}%", response.confidence_score * 100.0);
                println!("   âš¡ Latency: {:?}", elapsed);
                println!("   ğŸ§  Reasoning: {}", response.reasoning);

                if !response.optimization_hints.is_empty() {
                    println!("   ğŸ’¡ Tesla Optimizations:");
                    for hint in &response.optimization_hints {
                        println!("      â€¢ {}", hint);
                    }
                }

                if let Some(ref math_analysis) = response.mathematical_analysis {
                    println!("   ğŸ”¢ Mathematical Analysis: {}", math_analysis);
                }
            }
            Err(e) => {
                println!("   âŒ Error: {}", e);
            }
        }
        println!();
    }

    // Show system metrics
    let system_status = neural_mux.get_system_health();
    println!("ğŸ“Š System Status:");
    println!("   Overall Health: {:?}", system_status.overall_health);
    println!("   Neural Mux: {:?}", system_status.neural_mux_status);
    println!("   Active CDN Services: {}", system_status.cdn_status.len());

    let metrics = neural_mux.get_metrics();
    println!("ğŸ“ˆ Performance Metrics:");
    println!("   Neural Operations: {}", metrics.neural_operations_total);
    println!("   Avg Routing Latency: {:.2}ms", metrics.avg_routing_latency_ms);
    println!("   Cache Hit Ratio: {:.1}%", metrics.cache_hit_ratio * 100.0);

    println!();
    println!("ğŸ† RESULT: Tesla-grade routing achieved with ZERO AI/ML dependencies!");
    println!("ğŸš€ Optional: Add Ollama (phi4-mini) for even more intelligence");
    println!("âš¡ Fallback: Advanced rule-based system rivals AI performance");

    Ok(())
}